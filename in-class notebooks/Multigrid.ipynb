{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multigrid\n",
    "\n",
    "Multigrid is one of the great algorithms for numerically solving PDEs; it is one of the few essentially optimal algorithms for solving a linear system of equations, since it computes the solution of an $N\\times N$ system in ${\\mathcal O}(N\\log(N))$ -- or even just ${\\mathcal O}(N)$ -- operations.  \n",
    "\n",
    "This notebook is meant to accompany a reading of [Section 4.6 of Randall LeVeque's text on finite difference methods](http://0-epubs.siam.org.library.kaust.edu.sa/doi/abs/10.1137/1.9780898717839.ch4).  Other good resources are cited there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import HTML\n",
    "\n",
    "# To make the text in plots easier to read:\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 18}\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi's Method\n",
    "Let's use Jacobi's method to solve the problem given by Eq. (4.82) in  the text. In the box below, we set up the grid, the right hand side,  the boundary values, and the true solution $u$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2**8-1                              # Number of grid points\n",
    "h=1./(m+1)                         # Mesh width\n",
    "x=np.linspace(0,1,m+2); x=x[1:-1]  # grid\n",
    "phi = lambda x: 20.* np.pi * x**3\n",
    "f = lambda x: -20 + 0.5*120*np.pi*x * np.cos(phi(x)) - 0.5*(60*np.pi*x**2)**2 * np.sin(phi(x))\n",
    "alpha=1.; beta=3.\n",
    "u_exact = lambda x: 1.+12.*x-10.*x**2 + 0.5*np.sin(phi(x))  # Exact solution on computational grid\n",
    "\n",
    "plt.plot(x,u_exact(x));\n",
    "plt.xlim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take 100 iterations with Jacobi's method and plot the result. Notice how we modify $F$ to incorporate the boundary conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = 1.\n",
    "U=np.linspace(alpha,beta,m)  # Just use a straight line as initial guess\n",
    "UU=[U]\n",
    "F=0.5*h**2*f(x)\n",
    "F[0]-=alpha/2.; F[-1]-=beta/2.    # Construct the RHS, including boundary conditions\n",
    "e=np.ones(m-1)\n",
    "G=0.5*(np.diag(e,-1)+np.diag(e,1))\n",
    "niter=100\n",
    "\n",
    "for i in range(niter):\n",
    "    U=(1.-omega)*U+omega*(np.dot(G,U)-F)\n",
    "    UU.append(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `omega` in the code above is the under-relaxation parameter mentioned in the text.  By setting it to 1 for now, we have the original Jacobi method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = np.linspace(0,1,1000); \n",
    "uf = 1.+12.*xf-10.*xf**2 + 0.5*np.sin(phi(xf))  # Exact solution on fine grid\n",
    "u = 1.+12.*x-10.*x**2 + 0.5*np.sin(phi(x))  # Exact solution on computational grid\n",
    "                       \n",
    "def underrelaxed_jacobi(i):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.set_xlim(0,1); ax.set_ylim(-3,6)\n",
    "    ax.plot(xf,uf,lw=2)\n",
    "    ax.plot(x,UU[i],'-',lw=2)\n",
    "    ax.plot(x,UU[i]-u,'-',lw=2)\n",
    "    plt.legend(['Exact','Jacobi','Error'],loc=2)\n",
    "    ax.set_title('# of iterations: '+str(i),fontsize=15);\n",
    "\n",
    "interact(underrelaxed_jacobi,i=widgets.IntSlider(min=0,max=niter,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the animation above and notice how the high-frequency components of the error are damped very quickly, but the low-frequency error barely changes.  This is because the matrix $G$ appearing in Jacobi's method is tridiagonal, so in a single iteration each solution point only 'feels' the values of its immediate neighbors.  It takes very many iterations for low-frequency information to propagate.  As we'll see, part of the power of multigrid lies in enabling information to propagate rapidly between distant points in the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-relaxation\n",
    "Try playing around with the number of Jacobi iterations and see how the error changes. Remember that the $p$th Fourier mode  \n",
    "$$u^p = \\sin(p\\pi x)$$  \n",
    "is reduced by a factor of \n",
    "\n",
    "$$|\\hat{\\gamma}_p|= |1-\\omega + \\omega\\cos(p\\pi h)| = 1 + \\omega(\\cos(p \\pi h) - 1)|.$$\n",
    "  \n",
    "The code below plots this range of values. Try changing $\\omega$ to $\\frac{2}{3}$ and notice how the second half of the eigenvalues (for $p\\ge m/2$) are all shifted to have smaller absolute value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=30; H=1./(M+1)\n",
    "omegas=np.linspace(0.,1.)\n",
    "p=np.arange(1,M+1)\n",
    "\n",
    "def damping(omega):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.set_xlim(0,M); ax.set_ylim(0,1)\n",
    "    ax.set_xlabel('p', fontsize=15)\n",
    "    ax.set_ylabel('$\\hat{\\gamma}$', fontsize=20)\n",
    "    line1, = ax.plot([],[],'o')\n",
    "    gamma = abs(1.+omega*(np.cos(p*np.pi*H)-1))\n",
    "    line1.set_data(p,gamma)\n",
    "    ax.set_title('$\\omega = %02.2f $' % omega, fontsize=20)\n",
    "\n",
    "interact(damping,omega=widgets.FloatSlider(min=0,max=1,step=0.01,value=1,description=r'$\\omega$'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for $\\omega=1$ the highest frequencies are also not damped much.  Can you choose a different $f$ or a different grid size above so that some very high-frequency modes appear to remain in the error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid representations of a given frequency\n",
    "The code below plots a mode of a certain frequency, and then shows how it is represented on grids with decreasing numbers of points.  Notice how a *low frequency* mode (i.e., one with many points per wavelength) on a fine grid becomes a *high frequency* mode (one with very few points per wavelength).\n",
    "\n",
    "Eventually, on grids with very few points, the mode is *aliased* to a completely different mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf=np.linspace(0,1,1000) # fine grid\n",
    "\n",
    "def sine_on_grid(m,p):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.set_xlim(0,1); ax.set_ylim(-1.2, 1.2)\n",
    "    ax.plot(xf, np.sin(p*np.pi*xf), '-r', lw=2, alpha=0.5)\n",
    "    x=np.linspace(0,1,m+2); # grid\n",
    "    ax.plot(x,np.sin(p*np.pi*x),'o-',lw=2)\n",
    "    ax.set_title('$\\sin($'+str(p)+'$\\pi x)$ with m='+str(m)+' points',fontsize=20)\n",
    "\n",
    "interact(sine_on_grid,m=widgets.IntSlider(min=1,max=63,value=15),\n",
    "         p=widgets.IntSlider(min=0,max=50,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restriction and Prolongation\n",
    "The multigrid idea is to solve successively on different grids, so that every mode has a small damping factor $\\hat{\\gamma}$ on some grid.\n",
    "\n",
    "In order to implement multigrid, we need a way to take a function with values on a fine grid and restrict it to its values on a coarser grid (restriction). We also need a way to take a function with values on a coarse grid and interpolate onto a fine grid (prolongation). The functions below do just this, using linear interpolation in the case of the prolongation operator. Make sure you understand what they are doing. You may find it helpful to look up slicing notation in the NumPy help online.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarsen(f):\n",
    "    return f[1::2]  # This slicing just takes the odd-numbered points\n",
    "\n",
    "def interpolate(f,alpha,beta):\n",
    "    m_coarse=len(f)\n",
    "    m_fine  =2*m_coarse+1\n",
    "    f_interp = np.zeros(m_fine)\n",
    "    f_interp[1::2]=f                          #Set the values of the odd numbered points\n",
    "    f_interp[2:-1:2]=0.5*(f[:-1]+f[1:])       #Set the values of the (interior) even numbered points\n",
    "    f_interp[0]=0.5*(f_interp[1]+alpha)     #Set the values of the endpoints\n",
    "    f_interp[-1]=0.5*(f_interp[-2]+beta)\n",
    "    return f_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction using a second grid\n",
    "\n",
    "Now we compute the residual $$r = f-AU$$ on the fine grid, coarsen it, and solve $$Ae=-r$$ for the approximate error on the coarse grid. Then interpolate and subtract the interpolated error from the fine grid solution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the residual\n",
    "A=2./h**2*(G-np.eye(m))\n",
    "F=f(x); F[0]-=alpha/h**2; F[-1]-=beta/h**2\n",
    "r=F-np.dot(A,U)\n",
    "print(max(abs(r)))\n",
    "omega=2./3.\n",
    "m2=(m-1)//2              # Number of points in coarse grid\n",
    "print(m2)\n",
    "h2=1./(m2+1)              # coarse mesh width\n",
    "x2=coarsen(x)             # coarse grid points\n",
    "r2=coarsen(r)             # residual restricted to coarse grid\n",
    "err2=np.zeros(m2)         # initial guess for the error\n",
    "e2=np.ones(m2-1); G2=0.5*(np.diag(e2,-1)+np.diag(e2,1))\n",
    "for i in range(3):                        #Solve Ae=-r by Jacobi iteration\n",
    "    err2=(1.-omega)*err2+omega*(np.dot(G2,err2)+0.5*h2**2*r2)\n",
    "err=interpolate(err2,0,0)     # interpolate the error\n",
    "print(err[0])\n",
    "U=U-err                   # and use it to correct our solution\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x,u,x,U,x,U-u)\n",
    "plt.legend(['Exact','Jacobi','Error'],loc='best');\n",
    "plt.xlim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in order to keep our multigrid code clean, we'll write a function to set up and take a fixed number of Jacobi iterations. The function returns the approximate solution and the residual.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jacobi(U,f,alpha,beta,m,nu):\n",
    "    \"\"\"Perform nu Jacobi iterations on a grid with m points, with initial guess U, right hand side function f and \n",
    "       Dirichlet boundary conditions with values alpha and beta.  The function returns both the approximate\n",
    "       solution and the residual.\"\"\"\n",
    "    omega=2./3.\n",
    "    h=1./(m+1)\n",
    "    F=0.5*h**2*f.copy()\n",
    "    F[0]-=alpha/2.; F[-1]-=beta/2.\n",
    "    e=np.ones(m-1)\n",
    "    G=0.5*(np.diag(e,-1)+np.diag(e,1))\n",
    "    for i in range(nu):\n",
    "        U=(1.-omega)*U + omega*(np.dot(G,U)-F)\n",
    "    A=2./h**2*(G-np.eye(m))\n",
    "    FF=f.copy(); FF[0]-=alpha/h**2; FF[-1]-=beta/h**2\n",
    "    rr=FF-np.dot(A,U)\n",
    "    return U,rr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Multigrid V-cycle</strong>  \n",
    "Now let's do a full V-cycle. Look carefully through the code below until you understand what it does.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10;\n",
    "m=2**k-1\n",
    "rdep=k-1  # Recursion depth; this is how many grids down we want to go\n",
    "          # rdep=k-1 gives a full V-cycle\n",
    "nu=3      # Number of Jacobi iterations to take at each step\n",
    "U=np.linspace(alpha,beta,m)  # Initial guess\n",
    "x=np.linspace(0,1,m+2); x=x[1:-1]  # grid\n",
    "phi = lambda x: 20.* np.pi * x**3\n",
    "u = 1.+12.*x-10.*x**2 + 0.5*np.sin(phi(x))\n",
    "f = lambda x: -20 + 0.5*120*np.pi*x * np.cos(phi(x)) - 0.5*(60*np.pi*x**2)**2 * np.sin(phi(x))\n",
    "alpha=1.; beta=3.\n",
    "F=f(x)\n",
    "r=[None]*(rdep+1); error=[None]*(rdep+1)        # This just initializes these lists to have the right length\n",
    "U,rr=Jacobi(U,F,alpha,beta,m,nu)  # Initial iteration on fine grid\n",
    "for i in range(1,rdep+1): # Going down\n",
    "    m=(m-1)//2 #  = 2**(k-i) - 1\n",
    "    r[i]=coarsen(rr)             # residual restricted to next coarser grid\n",
    "    error[i],rr=Jacobi(np.zeros(m),-r[i],0.,0.,m,nu)\n",
    "for i in range(1,rdep): # Coming up\n",
    "    m=2*m+1\n",
    "    err=error[rdep-i]-interpolate(error[rdep+1-i],0,0)     # Interpolate and subtract the correction\n",
    "    error[-i-1],rr=Jacobi(err,-r[rdep-i],0.,0.,m,nu)\n",
    "m=2*m+1\n",
    "U=U-interpolate(error[1],0,0)                   # final solution correction\n",
    "U,rr=Jacobi(U,F,alpha,beta,m,nu)                #Final iterations on original grid\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x,u,x,U,'-',x,U-u,lw=2)\n",
    "plt.legend(['Exact','Jacobi','Error'],loc='best')\n",
    "plt.xlim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have saved the errors on each grid, we can plot them to see how they represent the accumulation of errors at different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 1), ylim=(-5,5))\n",
    "line1, = ax.plot([],[],'-ok',lw=2)\n",
    "\n",
    "def fplot(i):\n",
    "    y = np.zeros(len(error[-i])+2)\n",
    "    y[1:-1] = error[-i]\n",
    "    m = len(y)\n",
    "    x=np.linspace(0,1,m);\n",
    "    line1.set_data(x,y)\n",
    "    return line1, \n",
    "\n",
    "anim = animation.FuncAnimation(fig, fplot, frames=range(1,len(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Now you have the basic ideas of multigrid.  Of course, for this 1-dimensional problem (where the system to be solved is tridiagonal) it does not provide a big advantage over more naive methods.  The power of multigrid is that it can be used in multiple dimensions, where the algebraic system is much more challenging for other methods.  Furthermore, multigrid can be applied to nonlinear and time-dependent problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #11:\n",
    "Modify the V-cycle code above to answer the following questions. Try to explain your results.  \n",
    "(a) How does the accuracy change as we change the number of Jacobi iterations performed at each step?  \n",
    "\n",
    "(b) Is it better to use a finer grid, or more Jacobi iterations if we want to improve the solution accuracy?  \n",
    "\n",
    "(c) What happens if we don't perform any Jacobi iterations in the \"up\" part of the V-cycle?  \n",
    "\n",
    "(d) What happens if we don't recurse all the way down to the 1-point grid?  \n",
    "\n",
    "(e) What happens if we use the original Jacobi method, with $\\omega=1$?  Does your answer change if you reduce the number of points in the finest grid to $2^6-1$?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #12\n",
    "Use the V-cycle code above to implement the full multigrid algorithm discussed in the text. You will probably find it helpful to write a Vcycle() function first.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
